<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>3 Exploring and Visualizing Data | Quantitative Research Methods for Political Science, Public Policy and Public Administration: 4th Edition With Applications in R</title>
  <meta name="description" content="3 Exploring and Visualizing Data | Quantitative Research Methods for Political Science, Public Policy and Public Administration: 4th Edition With Applications in R">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="3 Exploring and Visualizing Data | Quantitative Research Methods for Political Science, Public Policy and Public Administration: 4th Edition With Applications in R" />
  <meta property="og:type" content="book" />
  
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="3 Exploring and Visualizing Data | Quantitative Research Methods for Political Science, Public Policy and Public Administration: 4th Edition With Applications in R" />
  
  
  

<meta name="author" content="Hank Jenkins-Smith">
<meta name="author" content="Joseph Ripberger">
<meta name="author" content="Gary Copeland">
<meta name="author" content="Matthew Nowlin">
<meta name="author" content="Tyler Hughes">
<meta name="author" content="Aaron Fister">
<meta name="author" content="Wesley Wehde">



  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="research-design.html">
<link rel="next" href="probability.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
</style>

</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface and Acknowledgments</a><ul>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html#copyright"><i class="fa fa-check"></i>Copyright</a></li>
</ul></li>
<li class="chapter" data-level="1" data-path="theories-and-social-science.html"><a href="theories-and-social-science.html"><i class="fa fa-check"></i><b>1</b> Theories and Social Science</a><ul>
<li class="chapter" data-level="1.1" data-path="theories-and-social-science.html"><a href="theories-and-social-science.html#the-scientific-method"><i class="fa fa-check"></i><b>1.1</b> The Scientific Method</a></li>
<li class="chapter" data-level="1.2" data-path="theories-and-social-science.html"><a href="theories-and-social-science.html#theory-and-empirical-research"><i class="fa fa-check"></i><b>1.2</b> Theory and Empirical Research</a><ul>
<li class="chapter" data-level="1.2.1" data-path="theories-and-social-science.html"><a href="theories-and-social-science.html#coherent-and-internally-consistent"><i class="fa fa-check"></i><b>1.2.1</b> Coherent and Internally Consistent</a></li>
<li class="chapter" data-level="1.2.2" data-path="theories-and-social-science.html"><a href="theories-and-social-science.html#theories-and-causality"><i class="fa fa-check"></i><b>1.2.2</b> Theories and Causality</a></li>
<li class="chapter" data-level="1.2.3" data-path="theories-and-social-science.html"><a href="theories-and-social-science.html#generation-of-testable-hypothesis"><i class="fa fa-check"></i><b>1.2.3</b> Generation of Testable Hypothesis</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="theories-and-social-science.html"><a href="theories-and-social-science.html#theory-and-functions"><i class="fa fa-check"></i><b>1.3</b> Theory and Functions</a></li>
<li class="chapter" data-level="1.4" data-path="theories-and-social-science.html"><a href="theories-and-social-science.html#theory-in-social-science"><i class="fa fa-check"></i><b>1.4</b> Theory in Social Science</a></li>
<li class="chapter" data-level="1.5" data-path="theories-and-social-science.html"><a href="theories-and-social-science.html#outline-of-the-book"><i class="fa fa-check"></i><b>1.5</b> Outline of the Book</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="research-design.html"><a href="research-design.html"><i class="fa fa-check"></i><b>2</b> Research Design</a><ul>
<li class="chapter" data-level="2.1" data-path="research-design.html"><a href="research-design.html#overview-of-the-research-process"><i class="fa fa-check"></i><b>2.1</b> Overview of the Research Process</a></li>
<li class="chapter" data-level="2.2" data-path="research-design.html"><a href="research-design.html#internal-and-external-validity"><i class="fa fa-check"></i><b>2.2</b> Internal and External Validity</a></li>
<li class="chapter" data-level="2.3" data-path="research-design.html"><a href="research-design.html#major-classes-of-designs"><i class="fa fa-check"></i><b>2.3</b> Major Classes of Designs</a></li>
<li class="chapter" data-level="2.4" data-path="research-design.html"><a href="research-design.html#threats-to-validity"><i class="fa fa-check"></i><b>2.4</b> Threats to Validity</a></li>
<li class="chapter" data-level="2.5" data-path="research-design.html"><a href="research-design.html#some-common-designs"><i class="fa fa-check"></i><b>2.5</b> Some Common Designs</a></li>
<li class="chapter" data-level="2.6" data-path="research-design.html"><a href="research-design.html#plan-meets-reality"><i class="fa fa-check"></i><b>2.6</b> Plan Meets Reality</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="exploring-and-visualizing-data.html"><a href="exploring-and-visualizing-data.html"><i class="fa fa-check"></i><b>3</b> Exploring and Visualizing Data</a><ul>
<li class="chapter" data-level="3.1" data-path="exploring-and-visualizing-data.html"><a href="exploring-and-visualizing-data.html#characterizing-data"><i class="fa fa-check"></i><b>3.1</b> Characterizing Data</a><ul>
<li class="chapter" data-level="3.1.1" data-path="exploring-and-visualizing-data.html"><a href="exploring-and-visualizing-data.html#central-tendency"><i class="fa fa-check"></i><b>3.1.1</b> Central Tendency</a></li>
<li class="chapter" data-level="3.1.2" data-path="exploring-and-visualizing-data.html"><a href="exploring-and-visualizing-data.html#level-of-measurement-and-central-tendency"><i class="fa fa-check"></i><b>3.1.2</b> Level of Measurement and Central Tendency</a></li>
<li class="chapter" data-level="3.1.3" data-path="exploring-and-visualizing-data.html"><a href="exploring-and-visualizing-data.html#moments"><i class="fa fa-check"></i><b>3.1.3</b> Moments</a></li>
<li class="chapter" data-level="3.1.4" data-path="exploring-and-visualizing-data.html"><a href="exploring-and-visualizing-data.html#first-moment-expected-value"><i class="fa fa-check"></i><b>3.1.4</b> First Moment – Expected Value</a></li>
<li class="chapter" data-level="3.1.5" data-path="exploring-and-visualizing-data.html"><a href="exploring-and-visualizing-data.html#the-second-moment-variance-and-standard-deviation"><i class="fa fa-check"></i><b>3.1.5</b> The Second Moment – Variance and Standard Deviation</a></li>
<li class="chapter" data-level="3.1.6" data-path="exploring-and-visualizing-data.html"><a href="exploring-and-visualizing-data.html#the-third-moment-skewness"><i class="fa fa-check"></i><b>3.1.6</b> The Third Moment – Skewness</a></li>
<li class="chapter" data-level="3.1.7" data-path="exploring-and-visualizing-data.html"><a href="exploring-and-visualizing-data.html#the-fourth-moment-kurtosis"><i class="fa fa-check"></i><b>3.1.7</b> The Fourth Moment – Kurtosis</a></li>
<li class="chapter" data-level="3.1.8" data-path="exploring-and-visualizing-data.html"><a href="exploring-and-visualizing-data.html#order-statistics"><i class="fa fa-check"></i><b>3.1.8</b> Order Statistics</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="exploring-and-visualizing-data.html"><a href="exploring-and-visualizing-data.html#summary"><i class="fa fa-check"></i><b>3.2</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="probability.html"><a href="probability.html"><i class="fa fa-check"></i><b>4</b> Probability</a><ul>
<li class="chapter" data-level="4.1" data-path="probability.html"><a href="probability.html#finding-probabilities"><i class="fa fa-check"></i><b>4.1</b> Finding Probabilities</a></li>
<li class="chapter" data-level="4.2" data-path="probability.html"><a href="probability.html#finding-probabilities-with-the-normal-curve"><i class="fa fa-check"></i><b>4.2</b> Finding Probabilities with the Normal Curve</a></li>
<li class="chapter" data-level="4.3" data-path="probability.html"><a href="probability.html#summary-1"><i class="fa fa-check"></i><b>4.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="inference.html"><a href="inference.html"><i class="fa fa-check"></i><b>5</b> Inference</a><ul>
<li class="chapter" data-level="5.1" data-path="inference.html"><a href="inference.html#inference-populations-and-samples"><i class="fa fa-check"></i><b>5.1</b> Inference: Populations and Samples</a><ul>
<li class="chapter" data-level="5.1.1" data-path="inference.html"><a href="inference.html#populations-and-samples"><i class="fa fa-check"></i><b>5.1.1</b> Populations and Samples</a></li>
<li class="chapter" data-level="5.1.2" data-path="inference.html"><a href="inference.html#sampling-and-knowing"><i class="fa fa-check"></i><b>5.1.2</b> Sampling and Knowing</a></li>
<li class="chapter" data-level="5.1.3" data-path="inference.html"><a href="inference.html#sampling-strategies"><i class="fa fa-check"></i><b>5.1.3</b> Sampling Strategies</a></li>
<li class="chapter" data-level="5.1.4" data-path="inference.html"><a href="inference.html#sampling-techniques"><i class="fa fa-check"></i><b>5.1.4</b> Sampling Techniques</a></li>
<li class="chapter" data-level="5.1.5" data-path="inference.html"><a href="inference.html#so-how-is-it-that-we-know"><i class="fa fa-check"></i><b>5.1.5</b> So How is it That We Know?</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="inference.html"><a href="inference.html#the-normal-distribution"><i class="fa fa-check"></i><b>5.2</b> The Normal Distribution</a><ul>
<li class="chapter" data-level="5.2.1" data-path="inference.html"><a href="inference.html#standardizing-a-normal-distribution-and-z-scores"><i class="fa fa-check"></i><b>5.2.1</b> Standardizing a Normal Distribution and Z-scores</a></li>
<li class="chapter" data-level="5.2.2" data-path="inference.html"><a href="inference.html#the-central-limit-theorem"><i class="fa fa-check"></i><b>5.2.2</b> The Central Limit Theorem</a></li>
<li class="chapter" data-level="5.2.3" data-path="inference.html"><a href="inference.html#populations-samples-and-symbols"><i class="fa fa-check"></i><b>5.2.3</b> Populations, Samples and Symbols</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="inference.html"><a href="inference.html#inferences-to-the-population-from-the-sample"><i class="fa fa-check"></i><b>5.3</b> Inferences to the Population from the Sample</a><ul>
<li class="chapter" data-level="5.3.1" data-path="inference.html"><a href="inference.html#confidence-intervals"><i class="fa fa-check"></i><b>5.3.1</b> Confidence Intervals</a></li>
<li class="chapter" data-level="5.3.2" data-path="inference.html"><a href="inference.html#the-logic-of-hypothesis-testing"><i class="fa fa-check"></i><b>5.3.2</b> The Logic of Hypothesis Testing</a></li>
<li class="chapter" data-level="5.3.3" data-path="inference.html"><a href="inference.html#some-miscellaneous-notes-about-hypothesis-testing"><i class="fa fa-check"></i><b>5.3.3</b> Some Miscellaneous Notes about Hypothesis Testing</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="inference.html"><a href="inference.html#differences-between-groups"><i class="fa fa-check"></i><b>5.4</b> Differences Between Groups</a><ul>
<li class="chapter" data-level="5.4.1" data-path="inference.html"><a href="inference.html#t-tests"><i class="fa fa-check"></i><b>5.4.1</b> <span class="math inline">\(t\)</span>-tests</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="inference.html"><a href="inference.html#summary-2"><i class="fa fa-check"></i><b>5.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="association-of-variables.html"><a href="association-of-variables.html"><i class="fa fa-check"></i><b>6</b> Association of Variables</a><ul>
<li class="chapter" data-level="6.1" data-path="association-of-variables.html"><a href="association-of-variables.html#cross-tabulation"><i class="fa fa-check"></i><b>6.1</b> Cross-Tabulation</a><ul>
<li class="chapter" data-level="6.1.1" data-path="association-of-variables.html"><a href="association-of-variables.html#crosstabulation-and-control"><i class="fa fa-check"></i><b>6.1.1</b> Crosstabulation and Control</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="association-of-variables.html"><a href="association-of-variables.html#covariance"><i class="fa fa-check"></i><b>6.2</b> Covariance</a></li>
<li class="chapter" data-level="6.3" data-path="association-of-variables.html"><a href="association-of-variables.html#correlation"><i class="fa fa-check"></i><b>6.3</b> Correlation</a></li>
<li class="chapter" data-level="6.4" data-path="association-of-variables.html"><a href="association-of-variables.html#scatterplots"><i class="fa fa-check"></i><b>6.4</b> Scatterplots</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="the-logic-of-ordinary-least-squares-estimation.html"><a href="the-logic-of-ordinary-least-squares-estimation.html"><i class="fa fa-check"></i><b>7</b> The Logic of Ordinary Least Squares Estimation</a><ul>
<li class="chapter" data-level="7.1" data-path="the-logic-of-ordinary-least-squares-estimation.html"><a href="the-logic-of-ordinary-least-squares-estimation.html#theoretical-models"><i class="fa fa-check"></i><b>7.1</b> Theoretical Models</a><ul>
<li class="chapter" data-level="7.1.1" data-path="the-logic-of-ordinary-least-squares-estimation.html"><a href="the-logic-of-ordinary-least-squares-estimation.html#deterministic-linear-model"><i class="fa fa-check"></i><b>7.1.1</b> Deterministic Linear Model</a></li>
<li class="chapter" data-level="7.1.2" data-path="the-logic-of-ordinary-least-squares-estimation.html"><a href="the-logic-of-ordinary-least-squares-estimation.html#stochastic-linear-model"><i class="fa fa-check"></i><b>7.1.2</b> Stochastic Linear Model</a></li>
<li class="chapter" data-level="7.1.3" data-path="the-logic-of-ordinary-least-squares-estimation.html"><a href="the-logic-of-ordinary-least-squares-estimation.html#assumptions-about-the-error-term"><i class="fa fa-check"></i><b>7.1.3</b> Assumptions about the Error Term</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="the-logic-of-ordinary-least-squares-estimation.html"><a href="the-logic-of-ordinary-least-squares-estimation.html#estimating-linear-models"><i class="fa fa-check"></i><b>7.2</b> Estimating Linear Models</a><ul>
<li class="chapter" data-level="7.2.1" data-path="the-logic-of-ordinary-least-squares-estimation.html"><a href="the-logic-of-ordinary-least-squares-estimation.html#residuals"><i class="fa fa-check"></i><b>7.2.1</b> Residuals</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="the-logic-of-ordinary-least-squares-estimation.html"><a href="the-logic-of-ordinary-least-squares-estimation.html#an-example-of-simple-regression"><i class="fa fa-check"></i><b>7.3</b> An Example of Simple Regression</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="linear-estimation-and-minimizing-error.html"><a href="linear-estimation-and-minimizing-error.html"><i class="fa fa-check"></i><b>8</b> Linear Estimation and Minimizing Error</a><ul>
<li class="chapter" data-level="8.1" data-path="linear-estimation-and-minimizing-error.html"><a href="linear-estimation-and-minimizing-error.html#minimizing-error-using-derivatives"><i class="fa fa-check"></i><b>8.1</b> Minimizing Error using Derivatives</a><ul>
<li class="chapter" data-level="8.1.1" data-path="linear-estimation-and-minimizing-error.html"><a href="linear-estimation-and-minimizing-error.html#rules-of-derivation"><i class="fa fa-check"></i><b>8.1.1</b> Rules of Derivation</a></li>
<li class="chapter" data-level="8.1.2" data-path="linear-estimation-and-minimizing-error.html"><a href="linear-estimation-and-minimizing-error.html#critical-points"><i class="fa fa-check"></i><b>8.1.2</b> Critical Points</a></li>
<li class="chapter" data-level="8.1.3" data-path="linear-estimation-and-minimizing-error.html"><a href="linear-estimation-and-minimizing-error.html#partial-derivation"><i class="fa fa-check"></i><b>8.1.3</b> Partial Derivation</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="linear-estimation-and-minimizing-error.html"><a href="linear-estimation-and-minimizing-error.html#deriving-ols-estimators"><i class="fa fa-check"></i><b>8.2</b> Deriving OLS Estimators</a><ul>
<li class="chapter" data-level="8.2.1" data-path="linear-estimation-and-minimizing-error.html"><a href="linear-estimation-and-minimizing-error.html#ols-derivation-of-hatalpha"><i class="fa fa-check"></i><b>8.2.1</b> OLS Derivation of <span class="math inline">\(\hat{\alpha}\)</span></a></li>
<li class="chapter" data-level="8.2.2" data-path="linear-estimation-and-minimizing-error.html"><a href="linear-estimation-and-minimizing-error.html#ols-derivation-of-hatbeta"><i class="fa fa-check"></i><b>8.2.2</b> OLS Derivation of <span class="math inline">\(\hat{\beta}\)</span></a></li>
<li class="chapter" data-level="8.2.3" data-path="linear-estimation-and-minimizing-error.html"><a href="linear-estimation-and-minimizing-error.html#interpreting-hatbeta-and-hatalpha"><i class="fa fa-check"></i><b>8.2.3</b> Interpreting <span class="math inline">\(\hat{\beta}\)</span> and <span class="math inline">\(\hat{\alpha}\)</span></a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="linear-estimation-and-minimizing-error.html"><a href="linear-estimation-and-minimizing-error.html#summary-3"><i class="fa fa-check"></i><b>8.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="bi-variate-hypothesis-testing-and-model-fit.html"><a href="bi-variate-hypothesis-testing-and-model-fit.html"><i class="fa fa-check"></i><b>9</b> Bi-Variate Hypothesis Testing and Model Fit</a><ul>
<li class="chapter" data-level="9.1" data-path="bi-variate-hypothesis-testing-and-model-fit.html"><a href="bi-variate-hypothesis-testing-and-model-fit.html#hypothesis-tests-for-regression-coefficients"><i class="fa fa-check"></i><b>9.1</b> Hypothesis Tests for Regression Coefficients</a><ul>
<li class="chapter" data-level="9.1.1" data-path="bi-variate-hypothesis-testing-and-model-fit.html"><a href="bi-variate-hypothesis-testing-and-model-fit.html#residual-standard-error"><i class="fa fa-check"></i><b>9.1.1</b> Residual Standard Error</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="bi-variate-hypothesis-testing-and-model-fit.html"><a href="bi-variate-hypothesis-testing-and-model-fit.html#measuring-goodness-of-fit"><i class="fa fa-check"></i><b>9.2</b> Measuring Goodness of Fit</a><ul>
<li class="chapter" data-level="9.2.1" data-path="bi-variate-hypothesis-testing-and-model-fit.html"><a href="bi-variate-hypothesis-testing-and-model-fit.html#sample-covariance-and-correlations"><i class="fa fa-check"></i><b>9.2.1</b> Sample Covariance and Correlations</a></li>
<li class="chapter" data-level="9.2.2" data-path="bi-variate-hypothesis-testing-and-model-fit.html"><a href="bi-variate-hypothesis-testing-and-model-fit.html#coefficient-of-determination-r2"><i class="fa fa-check"></i><b>9.2.2</b> Coefficient of Determination: <span class="math inline">\(R^{2}\)</span></a></li>
<li class="chapter" data-level="9.2.3" data-path="bi-variate-hypothesis-testing-and-model-fit.html"><a href="bi-variate-hypothesis-testing-and-model-fit.html#visualizing-bivariate-regression"><i class="fa fa-check"></i><b>9.2.3</b> Visualizing Bivariate Regression</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="bi-variate-hypothesis-testing-and-model-fit.html"><a href="bi-variate-hypothesis-testing-and-model-fit.html#summary-4"><i class="fa fa-check"></i><b>9.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="ols-assumptions-and-simple-regression-diagnostics.html"><a href="ols-assumptions-and-simple-regression-diagnostics.html"><i class="fa fa-check"></i><b>10</b> OLS Assumptions and Simple Regression Diagnostics</a><ul>
<li class="chapter" data-level="10.1" data-path="ols-assumptions-and-simple-regression-diagnostics.html"><a href="ols-assumptions-and-simple-regression-diagnostics.html#a-recap-of-modeling-assumptions"><i class="fa fa-check"></i><b>10.1</b> A Recap of Modeling Assumptions</a></li>
<li class="chapter" data-level="10.2" data-path="ols-assumptions-and-simple-regression-diagnostics.html"><a href="ols-assumptions-and-simple-regression-diagnostics.html#when-things-go-bad-with-residuals"><i class="fa fa-check"></i><b>10.2</b> When Things Go Bad with Residuals</a><ul>
<li class="chapter" data-level="10.2.1" data-path="ols-assumptions-and-simple-regression-diagnostics.html"><a href="ols-assumptions-and-simple-regression-diagnostics.html#outlier-data"><i class="fa fa-check"></i><b>10.2.1</b> “Outlier” Data</a></li>
<li class="chapter" data-level="10.2.2" data-path="ols-assumptions-and-simple-regression-diagnostics.html"><a href="ols-assumptions-and-simple-regression-diagnostics.html#non-constant-variance"><i class="fa fa-check"></i><b>10.2.2</b> Non-Constant Variance</a></li>
<li class="chapter" data-level="10.2.3" data-path="ols-assumptions-and-simple-regression-diagnostics.html"><a href="ols-assumptions-and-simple-regression-diagnostics.html#non-linearity-in-the-parameters"><i class="fa fa-check"></i><b>10.2.3</b> Non-Linearity in the Parameters</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="ols-assumptions-and-simple-regression-diagnostics.html"><a href="ols-assumptions-and-simple-regression-diagnostics.html#application-of-residual-diagnostics"><i class="fa fa-check"></i><b>10.3</b> Application of Residual Diagnostics</a><ul>
<li class="chapter" data-level="10.3.1" data-path="ols-assumptions-and-simple-regression-diagnostics.html"><a href="ols-assumptions-and-simple-regression-diagnostics.html#testing-for-non-linearity"><i class="fa fa-check"></i><b>10.3.1</b> Testing for Non-Linearity</a></li>
<li class="chapter" data-level="10.3.2" data-path="ols-assumptions-and-simple-regression-diagnostics.html"><a href="ols-assumptions-and-simple-regression-diagnostics.html#testing-for-normality-in-model-residuals"><i class="fa fa-check"></i><b>10.3.2</b> Testing for Normality in Model Residuals</a></li>
<li class="chapter" data-level="10.3.3" data-path="ols-assumptions-and-simple-regression-diagnostics.html"><a href="ols-assumptions-and-simple-regression-diagnostics.html#testing-for-non-constant-variance-in-the-residuals"><i class="fa fa-check"></i><b>10.3.3</b> Testing for Non-Constant Variance in the Residuals</a></li>
<li class="chapter" data-level="10.3.4" data-path="ols-assumptions-and-simple-regression-diagnostics.html"><a href="ols-assumptions-and-simple-regression-diagnostics.html#examining-outlier-data"><i class="fa fa-check"></i><b>10.3.4</b> Examining Outlier Data</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="ols-assumptions-and-simple-regression-diagnostics.html"><a href="ols-assumptions-and-simple-regression-diagnostics.html#so-now-what-implications-of-residual-analysis"><i class="fa fa-check"></i><b>10.4</b> So Now What? Implications of Residual Analysis</a></li>
<li class="chapter" data-level="10.5" data-path="ols-assumptions-and-simple-regression-diagnostics.html"><a href="ols-assumptions-and-simple-regression-diagnostics.html#summary-5"><i class="fa fa-check"></i><b>10.5</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html"><i class="fa fa-check"></i><b>11</b> Introduction to Multiple Regression</a><ul>
<li class="chapter" data-level="11.1" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html#matrix-algebra-and-multiple-regression"><i class="fa fa-check"></i><b>11.1</b> Matrix Algebra and Multiple Regression</a></li>
<li class="chapter" data-level="11.2" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html#the-basics-of-matrix-algebra"><i class="fa fa-check"></i><b>11.2</b> The Basics of Matrix Algebra</a><ul>
<li class="chapter" data-level="11.2.1" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html#matrix-basics"><i class="fa fa-check"></i><b>11.2.1</b> Matrix Basics</a></li>
<li class="chapter" data-level="11.2.2" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html#vectors"><i class="fa fa-check"></i><b>11.2.2</b> Vectors</a></li>
<li class="chapter" data-level="11.2.3" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html#matrix-operations"><i class="fa fa-check"></i><b>11.2.3</b> Matrix Operations</a></li>
<li class="chapter" data-level="11.2.4" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html#transpose"><i class="fa fa-check"></i><b>11.2.4</b> Transpose</a></li>
<li class="chapter" data-level="11.2.5" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html#adding-matrices"><i class="fa fa-check"></i><b>11.2.5</b> Adding Matrices</a></li>
<li class="chapter" data-level="11.2.6" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html#multiplication-of-matrices"><i class="fa fa-check"></i><b>11.2.6</b> Multiplication of Matrices</a></li>
<li class="chapter" data-level="11.2.7" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html#identity-matrices"><i class="fa fa-check"></i><b>11.2.7</b> Identity Matrices</a></li>
<li class="chapter" data-level="11.2.8" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html#matrix-inversion"><i class="fa fa-check"></i><b>11.2.8</b> Matrix Inversion</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html#ols-regression-in-matrix-form"><i class="fa fa-check"></i><b>11.3</b> OLS Regression in Matrix Form</a></li>
<li class="chapter" data-level="11.4" data-path="introduction-to-multiple-regression.html"><a href="introduction-to-multiple-regression.html#summary-6"><i class="fa fa-check"></i><b>11.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="12" data-path="the-logic-of-multiple-regression.html"><a href="the-logic-of-multiple-regression.html"><i class="fa fa-check"></i><b>12</b> The Logic of Multiple Regression</a><ul>
<li class="chapter" data-level="12.1" data-path="the-logic-of-multiple-regression.html"><a href="the-logic-of-multiple-regression.html#theoretical-specification"><i class="fa fa-check"></i><b>12.1</b> Theoretical Specification</a><ul>
<li class="chapter" data-level="12.1.1" data-path="the-logic-of-multiple-regression.html"><a href="the-logic-of-multiple-regression.html#assumptions-of-ols-regression"><i class="fa fa-check"></i><b>12.1.1</b> Assumptions of OLS Regression</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="the-logic-of-multiple-regression.html"><a href="the-logic-of-multiple-regression.html#partial-effects"><i class="fa fa-check"></i><b>12.2</b> Partial Effects</a></li>
<li class="chapter" data-level="12.3" data-path="the-logic-of-multiple-regression.html"><a href="the-logic-of-multiple-regression.html#multiple-regression-example"><i class="fa fa-check"></i><b>12.3</b> Multiple Regression Example</a><ul>
<li class="chapter" data-level="12.3.1" data-path="the-logic-of-multiple-regression.html"><a href="the-logic-of-multiple-regression.html#hypothesis-testing-and-t-tests"><i class="fa fa-check"></i><b>12.3.1</b> Hypothesis Testing and <span class="math inline">\(t\)</span>-tests</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="the-logic-of-multiple-regression.html"><a href="the-logic-of-multiple-regression.html#summary-7"><i class="fa fa-check"></i><b>12.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="multiple-regression-and-model-building.html"><a href="multiple-regression-and-model-building.html"><i class="fa fa-check"></i><b>13</b> Multiple Regression and Model Building</a><ul>
<li class="chapter" data-level="13.1" data-path="multiple-regression-and-model-building.html"><a href="multiple-regression-and-model-building.html#model-building"><i class="fa fa-check"></i><b>13.1</b> Model Building</a><ul>
<li class="chapter" data-level="13.1.1" data-path="multiple-regression-and-model-building.html"><a href="multiple-regression-and-model-building.html#theory-and-hypotheses"><i class="fa fa-check"></i><b>13.1.1</b> Theory and Hypotheses</a></li>
<li class="chapter" data-level="13.1.2" data-path="multiple-regression-and-model-building.html"><a href="multiple-regression-and-model-building.html#empirical-indicators"><i class="fa fa-check"></i><b>13.1.2</b> Empirical Indicators</a></li>
<li class="chapter" data-level="13.1.3" data-path="multiple-regression-and-model-building.html"><a href="multiple-regression-and-model-building.html#risks-in-model-building"><i class="fa fa-check"></i><b>13.1.3</b> Risks in Model Building</a></li>
</ul></li>
<li class="chapter" data-level="13.2" data-path="multiple-regression-and-model-building.html"><a href="multiple-regression-and-model-building.html#evils-of-stepwise-regression"><i class="fa fa-check"></i><b>13.2</b> Evils of Stepwise Regression</a></li>
<li class="chapter" data-level="13.3" data-path="multiple-regression-and-model-building.html"><a href="multiple-regression-and-model-building.html#summary-8"><i class="fa fa-check"></i><b>13.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="topics-in-multiple-regression.html"><a href="topics-in-multiple-regression.html"><i class="fa fa-check"></i><b>14</b> Topics in Multiple Regression</a><ul>
<li class="chapter" data-level="14.1" data-path="topics-in-multiple-regression.html"><a href="topics-in-multiple-regression.html#dummy-variables"><i class="fa fa-check"></i><b>14.1</b> Dummy Variables</a></li>
<li class="chapter" data-level="14.2" data-path="topics-in-multiple-regression.html"><a href="topics-in-multiple-regression.html#interaction-effects"><i class="fa fa-check"></i><b>14.2</b> Interaction Effects</a></li>
<li class="chapter" data-level="14.3" data-path="topics-in-multiple-regression.html"><a href="topics-in-multiple-regression.html#standardized-regression-coefficients"><i class="fa fa-check"></i><b>14.3</b> Standardized Regression Coefficients</a></li>
<li class="chapter" data-level="14.4" data-path="topics-in-multiple-regression.html"><a href="topics-in-multiple-regression.html#summary-9"><i class="fa fa-check"></i><b>14.4</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="15" data-path="the-art-of-regression-diagnostics.html"><a href="the-art-of-regression-diagnostics.html"><i class="fa fa-check"></i><b>15</b> The Art of Regression Diagnostics</a><ul>
<li class="chapter" data-level="15.1" data-path="the-art-of-regression-diagnostics.html"><a href="the-art-of-regression-diagnostics.html#ols-error-assumptions-revisited"><i class="fa fa-check"></i><b>15.1</b> OLS Error Assumptions Revisited</a></li>
<li class="chapter" data-level="15.2" data-path="the-art-of-regression-diagnostics.html"><a href="the-art-of-regression-diagnostics.html#ols-diagnostic-techniques"><i class="fa fa-check"></i><b>15.2</b> OLS Diagnostic Techniques</a><ul>
<li class="chapter" data-level="15.2.1" data-path="the-art-of-regression-diagnostics.html"><a href="the-art-of-regression-diagnostics.html#non-linearity"><i class="fa fa-check"></i><b>15.2.1</b> Non-Linearity</a></li>
<li class="chapter" data-level="15.2.2" data-path="the-art-of-regression-diagnostics.html"><a href="the-art-of-regression-diagnostics.html#non-constant-variance-or-heteroscedasticity"><i class="fa fa-check"></i><b>15.2.2</b> Non-Constant Variance, or Heteroscedasticity</a></li>
<li class="chapter" data-level="15.2.3" data-path="the-art-of-regression-diagnostics.html"><a href="the-art-of-regression-diagnostics.html#independence-of-e"><i class="fa fa-check"></i><b>15.2.3</b> Independence of <span class="math inline">\(E\)</span></a></li>
<li class="chapter" data-level="15.2.4" data-path="the-art-of-regression-diagnostics.html"><a href="the-art-of-regression-diagnostics.html#normality-of-the-residuals"><i class="fa fa-check"></i><b>15.2.4</b> Normality of the Residuals</a></li>
<li class="chapter" data-level="15.2.5" data-path="the-art-of-regression-diagnostics.html"><a href="the-art-of-regression-diagnostics.html#outliers-leverage-and-influence"><i class="fa fa-check"></i><b>15.2.5</b> Outliers, Leverage, and Influence</a></li>
<li class="chapter" data-level="15.2.6" data-path="the-art-of-regression-diagnostics.html"><a href="the-art-of-regression-diagnostics.html#outliers"><i class="fa fa-check"></i><b>15.2.6</b> Outliers</a></li>
<li class="chapter" data-level="15.2.7" data-path="the-art-of-regression-diagnostics.html"><a href="the-art-of-regression-diagnostics.html#multicollinearity"><i class="fa fa-check"></i><b>15.2.7</b> Multicollinearity</a></li>
</ul></li>
<li class="chapter" data-level="15.3" data-path="the-art-of-regression-diagnostics.html"><a href="the-art-of-regression-diagnostics.html#summary-10"><i class="fa fa-check"></i><b>15.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="16" data-path="logit-regression.html"><a href="logit-regression.html"><i class="fa fa-check"></i><b>16</b> Logit Regression</a><ul>
<li class="chapter" data-level="16.1" data-path="logit-regression.html"><a href="logit-regression.html#generalized-linear-models"><i class="fa fa-check"></i><b>16.1</b> Generalized Linear Models</a></li>
<li class="chapter" data-level="16.2" data-path="logit-regression.html"><a href="logit-regression.html#logit-estimation"><i class="fa fa-check"></i><b>16.2</b> Logit Estimation</a><ul>
<li class="chapter" data-level="16.2.1" data-path="logit-regression.html"><a href="logit-regression.html#logit-hypothesis-tests"><i class="fa fa-check"></i><b>16.2.1</b> Logit Hypothesis Tests</a></li>
<li class="chapter" data-level="16.2.2" data-path="logit-regression.html"><a href="logit-regression.html#goodness-of-fit"><i class="fa fa-check"></i><b>16.2.2</b> Goodness of Fit</a></li>
<li class="chapter" data-level="16.2.3" data-path="logit-regression.html"><a href="logit-regression.html#interpreting-logits"><i class="fa fa-check"></i><b>16.2.3</b> Interpreting Logits</a></li>
</ul></li>
<li class="chapter" data-level="16.3" data-path="logit-regression.html"><a href="logit-regression.html#summary-11"><i class="fa fa-check"></i><b>16.3</b> Summary</a></li>
</ul></li>
<li class="chapter" data-level="17" data-path="appendix-basic-r.html"><a href="appendix-basic-r.html"><i class="fa fa-check"></i><b>17</b> Appendix: Basic R</a><ul>
<li class="chapter" data-level="17.1" data-path="appendix-basic-r.html"><a href="appendix-basic-r.html#introduction-to-r"><i class="fa fa-check"></i><b>17.1</b> Introduction to R</a></li>
<li class="chapter" data-level="17.2" data-path="appendix-basic-r.html"><a href="appendix-basic-r.html#downloading-r-and-rstudio"><i class="fa fa-check"></i><b>17.2</b> Downloading R and RStudio</a></li>
<li class="chapter" data-level="17.3" data-path="appendix-basic-r.html"><a href="appendix-basic-r.html#introduction-to-programming"><i class="fa fa-check"></i><b>17.3</b> Introduction to Programming</a></li>
<li class="chapter" data-level="17.4" data-path="appendix-basic-r.html"><a href="appendix-basic-r.html#uploadingreading-data"><i class="fa fa-check"></i><b>17.4</b> Uploading/Reading Data</a></li>
<li class="chapter" data-level="17.5" data-path="appendix-basic-r.html"><a href="appendix-basic-r.html#data-manipulation-in-r"><i class="fa fa-check"></i><b>17.5</b> Data Manipulation in R</a></li>
<li class="chapter" data-level="17.6" data-path="appendix-basic-r.html"><a href="appendix-basic-r.html#savingwriting-data"><i class="fa fa-check"></i><b>17.6</b> Saving/Writing Data</a></li>
<li class="chapter" data-level="17.7" data-path="appendix-basic-r.html"><a href="appendix-basic-r.html#the-tidyverse"><i class="fa fa-check"></i><b>17.7</b> The Tidyverse</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Quantitative Research Methods for Political Science, Public Policy and Public Administration: 4th Edition With Applications in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="exploring-and-visualizing-data" class="section level1">
<h1><span class="header-section-number">3</span> Exploring and Visualizing Data</h1>
<p>You have your plan, you carry out your plan by getting out and collecting your data, and then you put your data into a file. You are excited to test your hypothesis, so you immediately run your multiple regression analysis and look at your output. You can do that (and probably will even if we advise against it), but before you can start to make sense of that output you need to look carefully at your data. You will want to know things like “how much spread do I have in my data” and “do I have any outliers”. (If you have limited spread, you may discover that it is hard to explain variation in something that is nearly a constant and if you have an outlier, your statistics may be focused on trying to explain that one case.)</p>
<p>In this chapter, we will identify the ways to characterize your data before you do serious analysis, both to understand what you are doing statistically and to error-check.</p>
<div id="characterizing-data" class="section level2">
<h2><span class="header-section-number">3.1</span> Characterizing Data</h2>
<p>What does it mean to characterize your data? First, it means knowing how many observations are contained in your data and the distribution of those observations over the range of your variable(s). What kinds of measures (interval, ordinal, nominal) do you have, and what are the ranges of valid measures for each variable? How many cases of missing (no data) or mis-coded (measures that fall outside the valid range) do you have? What do the coded values represent? While seemingly trivial, checking and evaluating your data for these attributes can save you major headaches later. For example, missing values for an observation often get a special code – say, “-99” – to distinguish them from valid observations. If you neglect to treat these values properly, R (or any other statistics program) will treat that value as if it were valid and thereby turn your results into a royal hairball. We know of cases in which even seasoned quantitative scholars have made the embarrassing mistake of failing to properly handle missing values in their analyses. In at least one case, a published paper had to be retracted for this reason. So don’t skimp on the most basic forms of data characterization!</p>
<p>The dataset used for purposes of illustration in this version of this text is taken from a survey of Oklahomans, conducted in 2016, by OU’s Center for Risk and Crisis Management. The survey question wording and background will be provided in class. However, for purposes of this chapter, note that the measure of <strong>ideology</strong> consists of a self-report of political ideology on a scale that ranges from 1 (strong liberal) to 7 (strong conservative); the measure of the <strong>perceived risk of climate change</strong> ranges from zero (no risk) to 10 (extreme risk). <strong>Age</strong> was measured in years.</p>
<p>It is often useful to graph the variables in your dataset to get a better idea of their distribution. In addition, we may want to compare the distribution of a variable to a theoretical distribution (typically a normal distribution). This can be accomplished in several ways, but we will show two here—a histogram and a density curve—and more will be discussed in later chapters. For now we examine the distribution of the variable measuring age. The red line on the density visualization presents the normal distribution given the mean and standard deviation of our variable.</p>
<p>A histogram creates intervals of equal length, called bins, and displays the frequency of observations in each of the bins. To produce a histogram in R simply use the <code>geom_histogram</code> command in the <code>ggplot2</code> package. Next, we plot the density of the observed data along with a normal curve. This can be done with the <code>geom_density</code> command in the <code>ggplot2</code> package.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(ggplot2)
<span class="kw">ggplot</span>(ds, <span class="kw">aes</span>(age)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_histogram</span>() </code></pre></div>
<div class="figure"><span id="fig:hist"></span>
<img src="_main_files/figure-html/hist-1.png" alt="Histogram" width="672" />
<p class="caption">
Figure 3.1: Histogram
</p>
</div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(ds, <span class="kw">aes</span>(age)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>() <span class="op">+</span>
<span class="st">   </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> dnorm, <span class="dt">args =</span> <span class="kw">list</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(ds<span class="op">$</span>age, <span class="dt">na.rm =</span> T), 
                                            <span class="dt">sd =</span> <span class="kw">sd</span>(ds<span class="op">$</span>age, <span class="dt">na.rm =</span> T)), <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>) </code></pre></div>
<div class="figure"><span id="fig:dens"></span>
<img src="_main_files/figure-html/dens-1.png" alt="Density Curve" width="672" />
<p class="caption">
Figure 3.2: Density Curve
</p>
</div>
<p>You can also get an overview of your data using a table known as a frequency distribution. The frequency distribution summarizes how often each value of your variable occurs in the dataset. If your variable has a limited number of values that it can take on, you can report all values, but if it has a large number of possible values (e.g., age of respondent), then you will want to create categories, or bins, to report those frequencies. In such cases, it is generally easier to make sense of the percentage distribution. Table <a href="exploring-and-visualizing-data.html#fig:ideo">3.3</a> is a frequency distribution for the ideology variable. From that table we see, for example, that about one-third of all respondents are moderates. We see the numbers decrease as we move away from that category, but not uniformly. There are a few more people on the conservative extreme than on the liberal side and that the number of people placing themselves in the penultimate categories on either end is greater than those towards the middle. The histogram and density curve would, of course, show the same pattern.</p>
<p>The other thing to watch for here (or in the charts) is whether there is an unusual observation. If one person scored 17 in this table, you could be pretty sure a coding error was made somewhere. You cannot find all your errors this way, but you can find some, including the ones that have the potential to most seriously adversely affect your analysis.</p>
<div class="figure"><span id="fig:ideo"></span>
<img src="freq-ideo.png" alt="Frequency Distribbution for Ideology" width="252" />
<p class="caption">
Figure 3.3: Frequency Distribbution for Ideology
</p>
</div>
<p>In R, we can obtain the data for the above table with the following functions:</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># frequency counts for each level</span>
<span class="kw">table</span>(ds<span class="op">$</span>ideol)</code></pre></div>
<pre><code>## 
##   1   2   3   4   5   6   7 
## 122 279 185 571 328 688 351</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># To view percentages</span>
<span class="kw">library</span>(dplyr)
<span class="kw">table</span>(ds<span class="op">$</span>ideol) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">prop.table</span>()</code></pre></div>
<pre><code>## 
##          1          2          3          4          5          6 
## 0.04833597 0.11053883 0.07329635 0.22622821 0.12995246 0.27258320 
##          7 
## 0.13906498</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># multiply the numbers by 100 </span>
<span class="kw">table</span>(ds<span class="op">$</span>ideol) <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">prop.table</span>() <span class="op">*</span><span class="st"> </span><span class="dv">100</span> </code></pre></div>
<pre><code>## 
##         1         2         3         4         5         6         7 
##  4.833597 11.053883  7.329635 22.622821 12.995246 27.258320 13.906498</code></pre>
<p>Having obtained a sample, it is important to be able to characterize that sample. In particular, it is important to understand the probability distributions associated with each variable in the sample.</p>
<div id="central-tendency" class="section level3">
<h3><span class="header-section-number">3.1.1</span> Central Tendency</h3>
<p>Measures of central tendency are useful because a single statistic can be used to describe the distribution. We focus on three measures of central tendency: the mean, the median, and the mode.</p>
<blockquote>
<p><strong>Measures of Central Tendency</strong></p>
<p>The Mean: The arithmetic average of the values</p>
<p>The Median: The value at the center of the distribution</p>
<p>The Mode: The most frequently occurring value</p>
</blockquote>
<p>We will primarily rely on the mean, because of its efficient property of representing the data. But medians – particularly when used in conjunction with the mean - can tell us a great deal about the shape of the distribution of our data. We will return to this point shortly.</p>
</div>
<div id="level-of-measurement-and-central-tendency" class="section level3">
<h3><span class="header-section-number">3.1.2</span> Level of Measurement and Central Tendency</h3>
<p>The three measures of central tendency – the mean, median, and mode – each tell us something different about our data, but each has some limitations as well (especially when used alone). Knowing the mode tells us what is most common, but we do not know how common and, using it alone, would not even leave us confident that it is an indicator of anything very <em>central</em>. When rolling in your data, it is generally a good idea to roll in all the descriptive statistics that you can to get a good feel for them.</p>
<p>One issue, though, is that your ability to use any statistic is dependent on the level of measurement for the variable. The mean requires you to add all your observations together. But you cannot perform mathematical functions on ordinal or nominal level measures. Your data must be measured at the interval level to calculate a meaningful mean. (If you ask R to calculate the mean student id number, it will, but what you get will be nonsense.) Finding the middle item in an order listing of your observations (the median) requires the ability to order your data, so your level of measurement must be at least ordinal. Therefore, if you have nominal level data, you can only report the mode (but no median or mean), so it is critical that you also look beyond central tendency to the overall distribution of the data.</p>
</div>
<div id="moments" class="section level3">
<h3><span class="header-section-number">3.1.3</span> Moments</h3>
<p>In addition to measures of central tendency, “moments” are important ways to characterize the shape of the distribution of a sample variable. Moments are applicable when the data measured is interval type (the level of measurement). The first four moments are those that are used most often.</p>
<div id="the-first-four-moments" class="section level4 unnumbered">
<h4>The First Four Moments</h4>
<ol style="list-style-type: decimal">
<li><em>Expected Value</em>: The expected value of a variable, <span class="math inline">\(E(X)\)</span> is its mean.</li>
</ol>
<p><span class="math inline">\(E(X) = \bar{X}=\frac{\sum X_{i}}{n}\)</span></p>
<ol start="2" style="list-style-type: decimal">
<li><em>Variance</em>: The variance of a variable concerns the way that the observed values are spread around either side of the mean.</li>
</ol>
<p><span class="math inline">\(s^{2}_{x}=\frac{\sum (X-\bar{X})^{2}}{(n-1)}\)</span></p>
<ol start="3" style="list-style-type: decimal">
<li><p><em>Skewness</em>: The skewness of a variable is a measure of its asymmetry.</p>
<p><span class="math inline">\(S = \frac{\sum (X-\bar{X})^{3}}{(n-1)}\)</span></p></li>
<li><p><em>Kurtosis</em>: The kurtosis of a variable is a measure of its peakedness.</p>
<p><span class="math inline">\(K = \frac{\sum (X-\bar{X})^{4}}{(n-1)}\)</span></p></li>
</ol>
</div>
</div>
<div id="first-moment-expected-value" class="section level3">
<h3><span class="header-section-number">3.1.4</span> First Moment – Expected Value</h3>
The <em>expected value</em> of a variable is the value you would obtain if you could multiply all possible values within a population by their probability of occurrence. Alternatively, it can be understood as the mean value for a population variable. An expected value is a theoretical number , because we usually cannot observe all possible occurrences of a variable. The mean value for a sample is the average value for the variable <span class="math inline">\(X\)</span>, and is calculated by adding the values of <span class="math inline">\(X\)</span> and dividing by the sample size <span class="math inline">\(n\)</span>:<br />

<span class="math display" id="eq:03-1">\[\begin{equation}
\bar{X} = \frac{(x_{1}+x_{2}+x_{3}+x_{n})}{n}
\tag{3.1}
\end{equation}\]</span>
This can be more compactly expressed as:
<span class="math display" id="eq:03-2">\[\begin{equation}
\bar{X}=\frac{\sum X_{i}}{n}
\tag{3.2}
\end{equation}\]</span>
<p>The mean of a variable can be calculated in <code>R</code> using the <code>mean</code> function. Here we illustrate the calculation of means for our measures of <code>ideology</code>, <code>age</code>, and <code>perceived risk of climate change</code>.<a href="#fn5" class="footnoteRef" id="fnref5"><sup>5</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(ds<span class="op">$</span>ideol, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## [1] 4.652932</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(ds<span class="op">$</span>age, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## [1] 60.36749</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(ds<span class="op">$</span>glbcc_risk, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## [1] 5.945978</code></pre>
</div>
<div id="the-second-moment-variance-and-standard-deviation" class="section level3">
<h3><span class="header-section-number">3.1.5</span> The Second Moment – Variance and Standard Deviation</h3>
The <em>variance</em> of a variable is a measure that illustrates how a variable is spread, or distributed, around its mean. For samples, it is expressed as:
<span class="math display" id="eq:03-3">\[\begin{equation}
s^{2}_{x}=\frac{\sum (X-\bar{X})^{2}}{(n-1)}
\tag{3.3}
\end{equation}\]</span>
<p>The population variance is expressed as: <span class="math inline">\(\sigma^{2}_{X}\)</span>.</p>
<p>Variance is measured in <em>squared</em> deviations from the mean, and the sum of these squared variations is termed the <strong>total sum of squares</strong>. Why squared deviations? Why not just sum the differences? While the latter strategy would seemingly be simpler, it would always sum to zero. By squaring the deviations we make them all positive, so the sum of squares will always be a positive number.</p>
<blockquote>
<p><strong>Total Sum of Squares</strong> is the squared summed total of the variation of a variable around its mean.</p>
</blockquote>
This can be expressed as:
<span class="math display" id="eq:03-4">\[\begin{equation}
TSS_{x} = \sum(X_{i}-\bar{X})^{2}
\tag{3.4}
\end{equation}\]</span>
therefore;
<span class="math display" id="eq:03-5">\[\begin{equation}
s^{2}_{x} = \frac{TSS_{x}}{(n-1)}
\tag{3.5}
\end{equation}\]</span>
The square root of variance, <span class="math inline">\(\sigma^{2}_{x}\)</span>, is the <em>standard deviation</em> (s.d.) of a variable, <span class="math inline">\(\sigma_{x}\)</span>. The sample s.d. is expressed as:
<span class="math display" id="eq:03-6">\[\begin{equation}
s_{x} = \sqrt{\frac{\sum(X-\bar{X})^{2}}{(n-1)}}
\tag{3.6}
\end{equation}\]</span>
<p>This can also be expressed as <span class="math inline">\(\sqrt{s^2_{x}}\)</span>. The standard deviation of a variable can be obtained in <code>R</code> with the <code>sd</code> function.<a href="#fn6" class="footnoteRef" id="fnref6"><sup>6</sup></a></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sd</span>(ds<span class="op">$</span>ideol, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## [1] 1.731246</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sd</span>(ds<span class="op">$</span>age, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## [1] 14.20894</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sd</span>(ds<span class="op">$</span>glbcc_risk, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>## [1] 3.071251</code></pre>
</div>
<div id="the-third-moment-skewness" class="section level3">
<h3><span class="header-section-number">3.1.6</span> The Third Moment – Skewness</h3>
<em>Skewness</em> is a measure of the asymmetry of a distribution. It is based on the third moment and is expressed as:
<span class="math display" id="eq:03-7">\[\begin{equation}
\frac{\sum (X-\bar{X})^{3}}{(n-1)}
\tag{3.7}
\end{equation}\]</span>
Skewness is calculated by dividing the third moment by the the cube of the s.d.
<span class="math display" id="eq:03-8">\[\begin{equation}
S = \frac{\frac{\sum (X-\bar{X})^{3}}{(n-1)}}{(\sqrt{\frac{\sum
    (X-\bar{X})^{2}}{(n-1)})^{3}}}
    \tag{3.8}
\end{equation}\]</span>
<p>Specifically, skewness refers to the position of the expected value (i.e., mean) of a variable distribution relative to its median. When the mean and median of a variable are roughly equal, <span class="math inline">\(\bar{Y} \approx Md_{Y}\)</span>, then the distribution is considered approximately symmetrical, <span class="math inline">\(S = 0\)</span>. This means that an equal proportion of the distribution of the variable lies on either side of the mean. However, when the mean is larger than the median, <span class="math inline">\(\bar{Y} &gt; Md_{Y}\)</span>, then the distribution has a <em>positive</em> skew, <span class="math inline">\(S &gt; 0\)</span>. When the median is larger than the mean, <span class="math inline">\(\bar{Y} &lt; Md_{Y}\)</span>, this is a <em>negative</em> skew, <span class="math inline">\(S &lt; 0\)</span>. This is illustrated in Figure <a href="exploring-and-visualizing-data.html#fig:disshape">3.4</a>. Note that for a normal distribution, <span class="math inline">\(S=0\)</span>.</p>
<div class="figure"><span id="fig:disshape"></span>
<img src="distroshapes.jpg" alt="Distributional Shapes"  />
<p class="caption">
Figure 3.4: Distributional Shapes
</p>
</div>
</div>
<div id="the-fourth-moment-kurtosis" class="section level3">
<h3><span class="header-section-number">3.1.7</span> The Fourth Moment – Kurtosis</h3>
The <em>kurtosis</em> of a distribution refers to the the peak of a variable (i.e., the mode) and the relative frequency of observations in the tails. It is based on the fourth moment which is expressed as:
<span class="math display" id="eq:03-9">\[\begin{equation}
\frac{\sum (X-\bar{X})^{4}}{(n-1)}
\tag{3.9}
\end{equation}\]</span>
Kurtosis is calculated by dividing the fourth moment by the square of the second moment (i.e., variance).
<span class="math display" id="eq:03-10">\[\begin{equation}
 K =  \frac{\frac{\sum (X-\bar{X})^{4}}{(n-1)}}{(\frac{\sum (X-\bar{X})^{2}}{(n-1)})^{2}}
 \tag{3.10}
\end{equation}\]</span>
<p>In general, higher kurtosis is indicative of a distribution where the variance is a result of low frequency yet more extreme observed values. In addition, when <span class="math inline">\(K &lt; 3\)</span>, the distribution is <em>platykurtic</em>, which is flatter and/or more “short-tailed” than a normal distribution. When <span class="math inline">\(K &gt; 3\)</span> the distribution is <em>leptokurtic</em>, which is a slim, high peak and long tails. In a normal distribution <span class="math inline">\(K=3\)</span>.</p>
</div>
<div id="order-statistics" class="section level3">
<h3><span class="header-section-number">3.1.8</span> Order Statistics</h3>
<p>Apart from central tendency and moments, probability distributions can also be characterized by <strong>order statistics</strong>. Order statistics are based on the position of a value in an ordered list. Typically, the list is ordered from low values to high values.</p>
<blockquote>
<p><strong>Order Statistics</strong></p>
<p>Summaries of values based on position in an ordered list of all values. Types of order statistics include the minimum value, the maximum value, the median, quartiles, and percentiles.</p>
<ul>
<li><em>Minimum Value</em>: The lowest value of a distribution</li>
<li><em>Maximum Value</em>: The highest value of a distribution</li>
<li><em>Median</em>: The value at the center of a distribution</li>
<li><em>Quartiles</em>: Divides the values into quarters</li>
<li><em>Percentiles</em>: Divides the values into hundredths</li>
</ul>
</blockquote>
<div id="median" class="section level4 unnumbered">
<h4>Median</h4>
<p>The <em>median</em> is the value at the center of the distribution, therefore 50% of the observations in the distribution will have values above the median and 50% will have values below. For samples with a <span class="math inline">\(n\)</span>-size that is an odd number, the median is simply the value in the middle. For example, with a sample consisting of the observed values of <span class="math inline">\(1, 2, 3, 4, 5\)</span>, the median is <span class="math inline">\(3\)</span>. Distributions with an even numbered <span class="math inline">\(n\)</span>-size, the median is the average of the two middle values. The median of a sample consisting of the observed values of <span class="math inline">\(1, 2, 3, 4, 5, 6\)</span> would be <span class="math inline">\(\frac{3+4}{2}\)</span> or 3.5.</p>
<p>The the median is the order statistic for central tendency. In addition, it is more “robust” in terms of extreme values than the mean. Extremely high values in a distribution can pull the mean higher, and extremely low values pull the mean lower. The median is less sensitive to these extreme values. The median is therefore the basis for “robust estimators,” to be discussed later in this book.</p>
</div>
<div id="quartiles" class="section level4 unnumbered">
<h4>Quartiles</h4>
<p><em>Quartiles</em> split the observations in a distribution into quarters. The first quartile, <span class="math inline">\(Q1\)</span>, consists of observations whose values are within the first 25% of the distribution. The values of the second quartile, <span class="math inline">\(Q2\)</span>, are contained within the first half (50%) of the distribution, and is marked by the distribution’s median. The third quartile, <span class="math inline">\(Q3\)</span>, includes the first 75% of the observations in the distribution.</p>
The interquartile range (IQR) measures the spread of the ordered values. It is calculated by subtracting <span class="math inline">\(Q1\)</span> from <span class="math inline">\(Q3\)</span>.
<span class="math display" id="eq:03-11">\[\begin{equation}
 IQR = Q_{3}-Q_{1}
 \tag{3.11}
\end{equation}\]</span>
<p>The IQR contains the middle 50% of the distribution.</p>
<p>We can visually examine the order statistics of a variable with a boxplot. A boxplot displays the range of the data, the first and third quartile, the median, and any outliers. The following returns a boxplot (Figure <a href="exploring-and-visualizing-data.html#fig:boxrsk">3.5</a>).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(ds, <span class="kw">aes</span>(<span class="st">&quot;&quot;</span>, glbcc_risk)) <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_boxplot</span>()</code></pre></div>
<div class="figure"><span id="fig:boxrsk"></span>
<img src="_main_files/figure-html/boxrsk-1.png" alt="Box-plot of Climate Change Risk" width="672" />
<p class="caption">
Figure 3.5: Box-plot of Climate Change Risk
</p>
</div>
</div>
<div id="percentiles" class="section level4 unnumbered">
<h4>Percentiles</h4>
<p><em>Percentiles-</em> list the data in hundredths. For example, scoring in the 99th percentile on the GRE means that 99% of the other test takers had a lower score. Percentiles can be incorporated with quartiles (and/or other order statistics) such that: - First Quartile: 25th percentile - Second Quartile: 50th percentile (the median) - Third Quartile: 75th percentile</p>
<p>Another way to compare a variable distribution to a theoretical distribution is with a quantile-comparison plot (qq plot). A qq plot displays the observed percentiles against those that would be expected in a normal distribution. This plot is often useful for examining the tails of the distribution, and deviations of a distribution from normality. This is shown in Figure <a href="exploring-and-visualizing-data.html#fig:qqrsk">3.6</a>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>(ds, <span class="kw">aes</span>(<span class="dt">sample =</span> glbcc_risk)) <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_qq</span>()</code></pre></div>
<div class="figure"><span id="fig:qqrsk"></span>
<img src="_main_files/figure-html/qqrsk-1.png" alt="QQ Plot of Climate Change Risk" width="672" />
<p class="caption">
Figure 3.6: QQ Plot of Climate Change Risk
</p>
</div>
<p>The qq plot provides an easy way to observe departures of a distribution from normality. For example, the plot shown in Figure <a href="exploring-and-visualizing-data.html#fig:qqrsk">3.6</a> indicates that the perceived risk measure has more observations in the tails of the distribution than would be expected if the variable was normally distributed.</p>
<p><code>R</code> provides several ways to examine the central tendency, moments, and order statistics for individual variables and for entire data sets. The <code>summary</code> function produces the minimum value, the first quartile, median, mean, third quartile, max value, and the number of missing values (Na’s).</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(ds<span class="op">$</span>ideol, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   1.000   4.000   5.000   4.653   6.000   7.000      23</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(ds<span class="op">$</span>age, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   18.00   52.00   62.00   60.37   70.00   99.00</code></pre>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">summary</span>(ds<span class="op">$</span>glbcc_risk, <span class="dt">na.rm=</span><span class="ot">TRUE</span>)</code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max.    NA&#39;s 
##   0.000   4.000   6.000   5.946   9.000  10.000      11</code></pre>
<p>We can also use the <code>describe</code> function in the <code>psych</code> package to obtain more descriptive statistics, including skewness and kurtosis.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(psych)
<span class="kw">describe</span>(ds<span class="op">$</span>ideol)</code></pre></div>
<pre><code>##    vars    n mean   sd median trimmed  mad min max range  skew kurtosis
## X1    1 2524 4.65 1.73      5    4.75 1.48   1   7     6 -0.45     -0.8
##      se
## X1 0.03</code></pre>
</div>
</div>
</div>
<div id="summary" class="section level2">
<h2><span class="header-section-number">3.2</span> Summary</h2>
<p>It is a serious mistake to begin your data analysis without understanding the basics of your data. Knowing their range, the general distribution of your data, the shape of that distribution, their central tendency, and so forth will give you important clues as you move through your analysis and interpretation and prevent serious errors from occurring. Readers also often need to know this information to provide a critical review of your work.</p>
<p>Overall, this chapter has focused on understanding and characterizing data. We refer to the early process of evaluating a data set as rolling in the data – getting to know the characteristic shapes of the distributions of each of the variables, the meanings of the scales, and the quality of the observations. The discussion of central tendency, moments, and order statistics are all tools that you can use for that purpose. As a practicing scholar, policy analyst, or public administration practitioner, this early stage in quantitative analysis is not optional; a failure to carefully and thoroughly understand your data can result in analytical disaster, excruciating embarrassment, and maybe even horrible encounters with the Killer Rabbit of Caerbannog.</p>
<p>Think of rolling in the data, then, as your version of the Holy Hand Grenade of Antioch.</p>

</div>
</div>
<div class="footnotes">
<hr />
<ol start="5">
<li id="fn5"><p>The <code>na.rm=TRUE</code> portion of the following code simply tells R to exclude the missing (NA) values from calculation.<a href="exploring-and-visualizing-data.html#fnref5">↩</a></p></li>
<li id="fn6"><p>What’s with those (n-1) terms in the denominators? These represent the “degrees of freedom” we need to calculate average squared deviations and variance. We “use up” one of our observations to be able to calculate the first deviation – because without that first observation, what would there be to deviate from?<a href="exploring-and-visualizing-data.html#fnref6">↩</a></p></li>
</ol>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="research-design.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="probability.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
